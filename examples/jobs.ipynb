{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Supacrawler Python SDK - Jobs Examples\n",
        "\n",
        "from supacrawler import SupacrawlerClient, JobCreateRequest\n",
        "import os\n",
        "\n",
        "client = SupacrawlerClient(api_key=os.environ.get(\"SUPACRAWLER_API_KEY\", \"YOUR_API_KEY\"))\n",
        "\n",
        "# Create a crawl job\n",
        "job = client.create_job(JobCreateRequest(\n",
        "    url=\"https://supabase.com/docs\",\n",
        "    type=\"crawl\",\n",
        "    format=\"markdown\",\n",
        "    link_limit=50,\n",
        "    depth=2,\n",
        "    include_subdomains=False,\n",
        "    render_js=False,\n",
        "    patterns=[\"/blog/*\", \"/docs/*\"],\n",
        "))\n",
        "print(job)\n",
        "\n",
        "# Poll until completion\n",
        "final = client.wait_for_job(job.job_id, interval_seconds=3.0, timeout_seconds=600.0)\n",
        "print(final.status)\n",
        "if final.status == \"completed\" and final.data is not None:\n",
        "    if hasattr(final.data, \"crawl_data\"):\n",
        "        print(\"Pages:\", len(final.data.crawl_data))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
